{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU shakespeare words generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCd736CkAsuG/nCwoUmhyx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madeira-International-Workshop-in-ML/2022_day_3/blob/main/GRU_shakespeare_words_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx1A54FyFCt8",
        "outputId": "00044e98-2ec6-4c24-be4c-ed31a8ecc949"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f32c358b370>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "Import the libraries\n",
        "\"\"\"\n",
        "\n",
        "# to develop the nn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np # data manipulation\n",
        "import random\n",
        "tf.device('gpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Download the Shakespeare dataset\n",
        "\"\"\"\n",
        "\n",
        "path = tf.keras.utils.get_file('shakespeare.txt',\n",
        "'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "MWx1Tp9TFIVx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Read the data\n",
        "\"\"\"\n",
        "\n",
        "# Read, then decode for py2 compat\n",
        "text = open(path, 'rb').read().decode(encoding='utf-8') \n",
        "\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')  \n",
        "vocab = sorted(set(text)) \n",
        "print(f'{len(vocab)} unique characters') # the unique characters in the file\n",
        "print(f'All unique characters: {vocab}') # all unique characters in the file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmVUf31zFIx-",
        "outputId": "f04a677e-eb52-4d73-d9c2-54ee0ed9327a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n",
            "65 unique characters\n",
            "All unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data Pre-Processing\n",
        "\"\"\"\n",
        "\n",
        "# produce the sequence of 60 characters shifting forward 3 characters \n",
        "maxlen = 60 # extract sequences of length 60\n",
        "step = 3 # number of character to shift forward \n",
        "sentences = []\t# holds extracted sequences\n",
        "nextChars = [] # holds the targets\n",
        "for c in range(0, len(text)-maxlen, step):\n",
        "\tsentences.append(text[c:c+maxlen])\n",
        "\tnextChars.append(text[c+maxlen])"
      ],
      "metadata": {
        "id": "xnyCXfSYFMPd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before training, convert the strings to a numerical representation using \n",
        "# vectorization\n",
        "chars = sorted(list(set(text))) # find all different characters\n",
        "vocabLen = len(chars)\n",
        "# assign a number to identify each character\n",
        "charIndices = dict((char, chars.index(char)) for char in chars) \n",
        "print (f'Index for all characters: {charIndices}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GiEZX-UHC8S",
        "outputId": "2a522729-b90d-4b04-b8cc-0de194daaa84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index for all characters: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# produce the dataset\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, charIndices[char]] = 1\n",
        "  y[i, charIndices[nextChars[i]]] = 1"
      ],
      "metadata": {
        "id": "gPBcZjiQHIlB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Building the nn\n",
        "\"\"\"\n",
        "\n",
        "# specify the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(layers.GRU(128, input_shape=(maxlen, vocabLen)))\n",
        "model.add(layers.Dense(vocabLen, activation=\"softmax\"))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# check the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArN-qXvAHel1",
        "outputId": "1c9fbcdc-15b6-4ab2-832d-18758ba71628"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 128)               74880     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 65)                8385      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83,265\n",
            "Trainable params: 83,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model.fit(x, y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elex9N35JRZJ",
        "outputId": "ccea5c29-0f4e-4e4b-ba9d-680eecae1c12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2905/2905 [==============================] - 453s 156ms/step - loss: 1.7982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f32b9196050>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sample the text characters according to the reweighted distribution\n",
        "\"\"\"\n",
        "\n",
        "# to run on GPU: Runtime->Change runtime type->Hardware Accelerator->GPU\n",
        "# para correr em GPU: Tempo de execução->Alterar tipo de tempo de execução\n",
        "# ->Acelerador de hardware->GPU\n",
        "\n",
        "# estimate the new charcter to include in the sentence\n",
        "def sample(preds):\n",
        "  # determine the probability for each character to be the next to be selected\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = preds / np.sum(preds)\n",
        "  # sample randomly once from a multinomial distribution characterized by the  \n",
        "  # probability of each character to be selected next, in oderer to create \n",
        "  # diversity in the words and avoid stucking the model in a repetitive\n",
        "  # sequence with very few characters\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "# randomly selcted a part of the text to work as test dataset (the seed)\n",
        "startIndex = random.randint(0, len(text) - maxlen - 1)\n",
        "seedText = text[startIndex: startIndex + maxlen]\n",
        "print('Seed to generate text: \"' + seedText + '\"')\n",
        "fullSentence = seedText\n",
        "for i in range(400): # estimate 400 characters after the seed\n",
        "  # produce the test data (seed)\n",
        "  sampled = np.zeros((1, maxlen, len(chars)))\n",
        "  # continue the previous sentence to inclune one new character\n",
        "  for t, char in enumerate(seedText):\n",
        "      sampled[0, t, charIndices[char]] = 1.\n",
        "  # predict one new character\n",
        "  preds = model.predict(sampled, verbose=0)[0]\n",
        "  nextIndex = sample(preds)\n",
        "  nextChar = chars[nextIndex]\n",
        "  # include the new character in the sentence\n",
        "  seedText += nextChar\n",
        "  # keep the same sime of the sentence to form the test dataset\n",
        "  seedText = seedText[1:]\n",
        "  fullSentence += nextChar # save the full sentence\n",
        "print('\\nGenerated text: \"' + str(fullSentence) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5F3XRmAHo_D",
        "outputId": "5c73f9f5-439d-4bf5-f220-183d5681dcce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed to generate text: \"tent to say it was for his country he did it to\n",
            "please his m\"\n",
            "\n",
            "Generated text: \"tent to say it was for his country he did it to\n",
            "please his myanged'd, my sincever\n",
            "Will a wartand pikery onsternates?\n",
            "\n",
            "KING RICHARD IIA:\n",
            "Gross dowald oo how abliny\n",
            "upon you say upon the seech me gopprous in his diest unstacio sham he\n",
            "thou word'g farsely faw an your, im you\n",
            "Morrave and he, guat, curpingan my\n",
            "plorde;\n",
            "Wis mauther enat not I dety soncy; you and the neal not, I doom to brong as the long and suppresss,\n",
            "And meess of cur afvence:\n",
            "Im you have so out\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Repeat with famous sentence\n",
        "\"\"\"\n",
        "\n",
        "# Famous sentence \n",
        "StartingText = \"To be, or not to be: that is the question. Cruel to be kind.\"\n",
        "\n",
        "seedText = StartingText[0 : maxlen]\n",
        "print('Seed to generate text: \"' + seedText + '\"')\n",
        "fullSentence = seedText\n",
        "for i in range(400): # estimate 400 characters after the seed\n",
        "  # produce the test data (seed)\n",
        "  sampled = np.zeros((1, maxlen, len(chars)))\n",
        "  # continue the previous sentence to inclune one new character\n",
        "  for t, char in enumerate(seedText):\n",
        "      sampled[0, t, charIndices[char]] = 1.\n",
        "  # predict one new character\n",
        "  preds = model.predict(sampled, verbose=0)[0]\n",
        "  nextIndex = sample(preds)\n",
        "  nextChar = chars[nextIndex]\n",
        "  # include the new character in the sentence\n",
        "  seedText += nextChar\n",
        "  # keep the same sime of the sentence to form the test dataset\n",
        "  seedText = seedText[1:]\n",
        "  fullSentence += nextChar # save the full sentence\n",
        "print('\\nGenerated text: \"' + str(fullSentence) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubRWt16IC1j",
        "outputId": "6bb7b292-4e3d-4031-948a-7482860764fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed to generate text: \"To be, or not to be: that is the question. Cruel to be kind.\"\n",
            "\n",
            "Generated text: \"To be, or not to be: that is the question. Cruel to be kind. Thor fearsace rifelds of relive me?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "If a reatonsther! broghing hather ny becrousongry dostwers, din sous now Marker you nother, sir a talinu to heal is thild bloody couss of heavenowhing theigh, be his, hen me pucted mine om heath,\n",
            "And hears' cherepion tell was,\n",
            "That you brough-.\n",
            "\n",
            "CARIOLANA:\n",
            "From! I'll, I hiver, I did to Marjunt,\n",
            "Tould that he disted not mary gonele man swe coun\"\n"
          ]
        }
      ]
    }
  ]
}